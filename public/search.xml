<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Contrastive Learning</title>
    <url>/2023/03/29/04-23-43/</url>
    <content><![CDATA[<h1 id="对比学习（学习笔记）"><a href="#对比学习（学习笔记）" class="headerlink" title="对比学习（学习笔记）"></a>对比学习（学习笔记）</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>NLP领域的Bert模型，对于这波图像领域的对比学习热潮，是具有启发和推动作用的。我们知道，Bert预训练模型，通过MLM任务的自监督学习，充分挖掘了模型从海量无标注文本中学习通用知识的能力。而图像领域的预训练，往往是有监督的，就是用ImageNet来进行预训练，但是在下游任务中Fine-tuning的效果，跟Bert在NLP下游任务中带来的性能提升，是没法比的。</p>
<span id="more"></span>
<p>因此，对比学习的出现就是要干NLP领域类似Bert预训练的事情，通过自监督学习，不依赖标注数据，要从无标注图像中自己学习知识。图像领域里的自监督可以分为两种类型：生成式自监督学习，判别式自监督学习。对比学习则是典型的判别式自监督学习，相对生成式自监督学习，对比学习的任务难度要低一些。</p>
<p>现有方法基本上可以划分为：基于负例的对比学习方法、基于对比聚类的方法、基于不对称网络结构的方法，以及基于冗余消除损失函数的方法。</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>对比学习</category>
      </categories>
      <tags>
        <tag>Contrastive Learning</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>衡量相似性的方法</title>
    <url>/2023/03/30/00-46-40/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>保持距离！ </p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<h2 id="相似性"><a href="#相似性" class="headerlink" title="相似性"></a>相似性</h2><p>对于深度学习的各种任务，我们常常需要最小化模型输出与真实标签之间的距离，我们往往采用均方误差，交叉熵等作为损失函数，换句话说，不管是拉近它们分布之间的距离，还是什么，都是在使它们这两个张量更为相似。因此我们任何能衡量两组数据的相似性的方法都可以作为损失函数。这里总结一下各种计算相似度的方法。</p>
<hr>
<h3 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a>余弦相似度</h3><blockquote>
<p><strong>余弦相似性</strong>通过测量两个<a href="https://baike.baidu.com/item/向量?fromModule=lemma_inlink">向量</a>的夹角的<a href="https://baike.baidu.com/item/余弦?fromModule=lemma_inlink">余弦</a>值来度量它们之间的相似性。0度角的余弦值是1，而其他任何角度的余弦值都不大于1；并且其最小值是-1。从而两个向量之间的角度的余弦值确定两个向量是否大致指向相同的方向。两个向量有相同的指向时，余弦相似度的值为1；两个向量夹角为90°时，余弦相似度的值为0；两个向量指向完全相反的方向时，余弦相似度的值为-1。这结果是与向量的长度无关的，仅仅与向量的指向方向相关。</p>
</blockquote>
<span id="more"></span>
<h4 id="计算方式："><a href="#计算方式：" class="headerlink" title="计算方式："></a>计算方式：</h4><p>两个向量间的余弦值可以通过使用欧几里得点积公式求出：</p>
<p><img src="/2023/03/30/00-46-40/image-20230330005905251.png" alt="image-20230330005905251" style="zoom:50%;"></p>
<p>给定两个属性向量，<em>A</em>和<em>B</em>，其余弦相似性<em>θ</em>由点积和向量长度计算出：</p>
<p><img src="/2023/03/30/00-46-40/image-20230330005954209.png" alt="image-20230330005954209" style="zoom:50%;"></p>
<h5 id="Pytorch代码："><a href="#Pytorch代码：" class="headerlink" title="Pytorch代码："></a>Pytorch代码：</h5><p><img src="/2023/03/30/00-46-40/image-20230330193750294.png" alt="image-20230330193750294" style="zoom:50%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#given x1 and x2</span></span><br><span class="line">cos = torch.nn.CosineSimilarity(dim=<span class="number">1</span>,eps=<span class="number">1e-8</span>) <span class="comment">#eps防止分母除到0</span></span><br><span class="line">output = cos(x1,x2)</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="感知相似性（Perceptual-Similarity）"><a href="#感知相似性（Perceptual-Similarity）" class="headerlink" title="感知相似性（Perceptual Similarity）"></a><strong>感知相似性（Perceptual Similarity）</strong></h3><blockquote>
<p>LPIPS：来源于CVPR2018的一篇论文《The Unreasonable Effectiveness of Deep Features as a Perceptual Metric》，该度量标准学习生成图像到Ground Truth的反向映射强制生成器学习从假图像中重构真实图像的反向映射，并优先处理它们之间的感知相似度，更符合人类的感知，可以用于衡量两个图片之间的相似度。</p>
</blockquote>
<h4 id="计算方法："><a href="#计算方法：" class="headerlink" title="计算方法："></a>计算方法：</h4><p><img src="/2023/03/30/00-46-40/image-20230330202419413.png" alt="image-20230330202419413" style="zoom:50%;"></p>
<p><img src="/2023/03/30/00-46-40/image-20230330202503729.png" alt="image-20230330202503729" style="zoom:30%;"></p>
<p>通过对各通道加和，空间平均每一层网络输出的特征图之间的距离。然后将得到的两个距离输入到评分网络中。$W_l$是与通道数同维度的可训练权重参数。其中$F$表示预训练特征提取模型，如Vgg，Alex等。</p>
<h5 id="Pytorch代码：-1"><a href="#Pytorch代码：-1" class="headerlink" title="Pytorch代码："></a>Pytorch代码：</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!pip install lpips</span></span><br><span class="line"><span class="keyword">import</span> lpips</span><br><span class="line">lpips_fn = lpips.LPIPS(net=<span class="string">&#x27;vgg&#x27;</span>)</span><br><span class="line">output = lpips_fn(x1,x2)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>DDPM(Denoising Diffusion Probabilistic Model)公式以及代码解析</title>
    <url>/2023/03/31/15-23-50/</url>
    <content><![CDATA[<h2 id="Diffusion-model之DDPM"><a href="#Diffusion-model之DDPM" class="headerlink" title="Diffusion model之DDPM"></a>Diffusion model之DDPM</h2><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>本文理论公式等不做详细推导，只做总结（<del>毕竟是给我自己看的，不是</del>），代码部分会详细解析。 </p>

            <i class="fa fa-quote-right"></i>
          </blockquote>
<hr>
<h3 id="Denoising-Diffusion-Probabilistic-Model"><a href="#Denoising-Diffusion-Probabilistic-Model" class="headerlink" title="Denoising Diffusion Probabilistic Model"></a>Denoising Diffusion Probabilistic Model</h3><h4 id="前向过程："><a href="#前向过程：" class="headerlink" title="前向过程："></a>前向过程：<img src="/2023/03/31/15-23-50/image-20230331160559333.png" alt="image-20230331160559333" style="zoom:50%;"></h4><p>通过从原始数据分布 $\mathbf{x}_0 \sim q(\mathbf{x}_0) $ 不断加高斯噪声，根据马尔可夫链的性质，在T趋于∞的时候可以使其成为一个平稳分布（标准高斯分布） $\mathbf{x}_T \sim \varphi(\mathbf{x})$即 $X \sim N(0,1)$ ，加噪的方差(可以理解为噪声的尺度)由 $\beta_t$控制,调节上一时刻的数据和加入噪声的比例，且随时间步T变化而变化。</p>
<span id="more"></span>
<p>每个时刻加噪后的分布可以表示为 $q(\mathbf{x}_{t}|\mathbf{x}_{t-1}) := \mathcal{N}(\mathbf{x}:\sqrt{1-\beta_t}\mathbf{x}_{t-1}),\beta_tI) $，整个扩散过程可以表示为：$q\left(\mathbf{x}_{1: T} \mid \mathbf{x}_{0}\right):=\prod_{t=1}^{T} q\left(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}\right)$。但一步一步加噪是否可以优化，考虑是否可以一步到位，于是便可以根据正态分布的可加性继续推导，用每一个时刻的上一时刻展开表示，其中做一个表示上的代换（ $\alpha_t = 1-\beta_t$ ），最后可以发现规律:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{x}_{t} & =\sqrt{\alpha_{t}} \mathbf{x}_{t-1}+\sqrt{1-\alpha_{t}} \epsilon_{t-1} \\
& =\sqrt{\alpha_{t}}\left(\sqrt{\alpha_{t-1}} \mathbf{x}_{t-2}+\sqrt{1-\alpha_{t-1}} \epsilon_{t-2}\right)+\sqrt{1-\alpha_{t}} \epsilon_{t-1} \\
& =\sqrt{\alpha_{t} \alpha_{t-1}} \mathbf{x}_{t-2}+\sqrt{ {\sqrt{\alpha_{t}-\alpha_{t} \alpha_{t-1}}}^{2}+{\sqrt{1-\alpha_{t}}}^{2}} \bar{\epsilon}_{t-2} \\
& =\sqrt{\alpha_{t} \alpha_{t-1}} \mathbf{x}_{t-2}+\sqrt{1-\alpha_{t} \alpha_{t-1}} \bar{\epsilon}_{t-2} \\
& =\ldots \\
& =\sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t}} \epsilon
\end{aligned}</script><p>即 $q\left(\mathbf{x}_{t} \mid \mathbf{x}_{0}\right)=\mathcal{N}\left(\mathbf{x}_{t} ; \sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0},\left(1-\bar{\alpha}_{t}\right) \mathbf{I}\right)$ ，从而我们可以一步生成任意时刻的图像：</p>
<p><img src="/2023/03/31/15-23-50/image-20230331164416748.png" alt="image-20230331164416748" style="zoom:50%;"></p>
<p>生成 $\mathbf{x}_{t}$的过程我们可以利用<a href="https://zhuanlan.zhihu.com/p/542478018">重参数化</a>技巧得到。</p>
<hr>
<h4 id="逆向过程："><a href="#逆向过程：" class="headerlink" title="逆向过程："></a>逆向过程：<img src="/2023/03/31/15-23-50/image-20230331230650193.png" alt="image-20230331230650193" style="zoom:50%;"></h4><p>逆向是一个去噪的过程，从一个随机高斯噪声开始，一步一步生成原始高清的图片，反向过程也定义为一个马尔可夫过程，要求 $t=0$时刻的数据，即要求 $p_\theta (\mathbf{x}_{0:T}) = p\left(\mathbf{x}_{T}\right) \prod_{t=1}^{T} p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)$，但这里是 $p_{\theta}\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}\right)$ 我们是无从得知。</p>
<p>这里我们利用贝叶斯公式进行一个展开：</p>
<script type="math/tex; mode=display">
p_{\theta}\left(\mathbf{x}_{t-1}\mid\mathbf{x}_{t},\mathbf{x}_{0}\right) = q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_{0}\right)=q\left(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}, \mathbf{x}_{0}\right) \frac{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{0}\right)}{q\left(\mathbf{x}_{t} \mid \mathbf{x}_{0}\right)}</script><p>带入正态分布的概率密度函数，展开并配方：</p>
<script type="math/tex; mode=display">
\begin{aligned}
q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_{0}\right) & =q\left(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}, \mathbf{x}_{0}\right) \frac{q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{0}\right)}{q\left(\mathbf{x}_{t} \mid \mathbf{x}_{0}\right)} \\
& \propto \exp \left(-\frac{1}{2}\left(\frac{\left(\mathbf{x}_{t}-\sqrt{\alpha_{t}} \mathbf{x}_{t-1}\right)^{2}}{\beta_{t}}+\frac{\left(\mathbf{x}_{t-1}-\sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_{0}\right)^{2}}{1-\bar{\alpha}_{t-1}}\right.\right.\left.\left.-\frac{\left(\mathbf{x}_{t}-\sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0}\right)^{2}}{1-\bar{\alpha}_{t}}\right)\right) \\
&=\exp \left(-\frac{1}{2}\left(\left(\frac{\alpha_{t}}{\beta_{t}}+\frac{1}{1-\bar{\alpha}_{t-1}}\right) \mathbf{x}_{t-1}^{2}-\left(\frac{2 \sqrt{\alpha_{t}}}{\beta_{t}} \mathbf{x}_{t}+\frac{2 \sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}} \mathbf{x}_{0}\right) \mathbf{x}_{t-1}\right.\right.\left.\left.+C\left(\mathbf{x}_{t}, \mathbf{x}_{0}\right)\right)\right)

\end{aligned}</script><p>配方后可以用一个新的分布表示:         </p>
<script type="math/tex; mode=display">
q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_{0}\right) ～ \mathcal{N}(\mathbf{x}_{t-1};\tilde{\mathbf{\mu}} (\mathbf{x}_t,\mathbf{x}_{0}),\tilde{\beta_t}\mathbf{I})</script><p>其中： </p>
<script type="math/tex; mode=display">
\begin{gather}
\tilde{\mathbf{\mu}} (\mathbf{x}_t,\mathbf{x}_{0})=\frac{\sqrt{\alpha_t}\left(1-\bar{\alpha}_{t-1}\right)}{1-\bar{\alpha}_t} \mathbf{x}_t+\frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1-\bar{\alpha}_t} \mathbf{x}_0   \\
\tilde{\beta}_t=1 /\left(\frac{\alpha_t}{\beta_t}+\frac{1}{1-\bar{\alpha}_{t-1}}\right)=1 /\left(\frac{\alpha_t-\bar{\alpha}_t+\beta_t}{\beta_t\left(1-\bar{\alpha}_{t-1}\right)}\right)=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \cdot \beta_t
\end{gather}</script><p>其中方差可以看出是一个定值，而均值和 $\mathbf{x}_t$、$\mathbf{x}_0$有关，$\mathbf{x}_t$是已知输入，$\mathbf{x}_0$可以由前向过程一步加噪的式子代入化简。</p>
<script type="math/tex; mode=display">
\begin{gather}
\mathbf{x}_t=\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon} \\
\mathbf{x}_0 = \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}\right) \\
\boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right)=\tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t-\sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t\right)\right)\right)=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t, t\right)\right)
\end{gather}</script><p>这里我们如果我们有这个均值和方差，便可以根据这两个参数从正态分布中采样出一个数据，即得到 $\mathbf{x}_{t-1}$。但是我们没有噪声 $\boldsymbol{\epsilon}$的信息，现在可以考虑用一个神经网络$\boldsymbol{\epsilon}_\theta$ 去学习这个$\boldsymbol{\epsilon}$的信息，也可以直接学习均值的信息（但论文实验表明直接预测均值效果不好）。于是考虑用一个conditional的Unet去预测，$\boldsymbol{\epsilon}_\theta = U net(\mathbf{x}_t,t)$，之后便可以从$\mathbf{x}_t$预测得到$\boldsymbol{\epsilon}$，进而Sample出$\mathbf{x}_{t-1}$，直到$\mathbf{x}_0$</p>
<script type="math/tex; mode=display">
\mathbf{x}_{t-1}=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t, t\right)\right)+\sigma_t \mathbf{z}</script><hr>
<h4 id="训练过程："><a href="#训练过程：" class="headerlink" title="训练过程："></a>训练过程：</h4><p><img src="/2023/03/31/15-23-50/image-20230401005008193.png" alt="image-20230401005008193" style="zoom:50%;"></p>
<ol>
<li>首先从我们的数据分布中sample出一个batch的数据 —&gt; B x C x H x W</li>
<li>然后对整个batch分配从均匀分布中随机采样出的t —&gt; B x 1 （每个样本的t不是相同的）</li>
<li>从标准正态分布中采样一个噪音，根据噪音和 $\mathbf{x}_{0}$利用公式直接生成 $\mathbf{x}_{t}$</li>
<li>根据生成的$\mathbf{x}_{t}$和$t$利用Unet预测一个噪音，和初始sample的噪声计算MSE loss</li>
<li>根据梯度优化Unet参数。</li>
</ol>
<h4 id="采样过程："><a href="#采样过程：" class="headerlink" title="采样过程："></a>采样过程：</h4><p><img src="/2023/03/31/15-23-50/image-20230401005051290.png" alt="image-20230401005051290" style="zoom:50%;"></p>
<ol>
<li>从标准正态分布中采样一个噪声作为 $\mathbf{x}_{T}$</li>
<li>执行T步循环：输入当前t和 $\mathbf{x}_{t}$，得到预测的 $\boldsymbol{\epsilon}_\theta$，根据公式计算均值和方差（DDPM里是固定的），然后从新的分布中利用重参数技巧重新采样获得上一时刻 $\mathbf{x}_{t-1}$。直到 $t=1$时结束。</li>
</ol>
<h3 id="代码解析："><a href="#代码解析：" class="headerlink" title="代码解析："></a>代码解析：</h3><blockquote>
<p>这里对Lucidrains大佬复现的Pytorch版DDPM代码进行分析。（<del>简直是优雅</del>）</p>
</blockquote>
<ul>
<li><a href="https://github.com/lucidrains/denoising-diffusion-pytorch">代码参考https://github.com/lucidrains/denoising-diffusion-pytorch</a></li>
</ul>
<h4 id="代码分析顺序："><a href="#代码分析顺序：" class="headerlink" title="代码分析顺序："></a>代码分析顺序：</h4><ul>
<li><h5 id="模型结构-—-gt-训练-—-gt-采样"><a href="#模型结构-—-gt-训练-—-gt-采样" class="headerlink" title="模型结构 $—&gt;$ 训练 $—&gt;$ 采样"></a>模型结构 $—&gt;$ 训练 $—&gt;$ 采样</h5></li>
</ul>
<h4 id="模型结构："><a href="#模型结构：" class="headerlink" title="模型结构："></a>模型结构：</h4><ol>
<li><h6 id="Unet：用于预测noise，是带有Conditional的Unet-x-t-，通过self-attention模块把Position-Embedding后的时间步-mathbf-T-融合到Unet中，从而能更好对于不同时刻的-mathbf-X-T-进行噪声的预测。训练后模型保存的就是这块的参数。"><a href="#Unet：用于预测noise，是带有Conditional的Unet-x-t-，通过self-attention模块把Position-Embedding后的时间步-mathbf-T-融合到Unet中，从而能更好对于不同时刻的-mathbf-X-T-进行噪声的预测。训练后模型保存的就是这块的参数。" class="headerlink" title="Unet：用于预测noise，是带有Conditional的Unet(x,t)，通过self-attention模块把Position Embedding后的时间步$\mathbf{T}$融合到Unet中，从而能更好对于不同时刻的 $\mathbf{X}_T$进行噪声的预测。训练后模型保存的就是这块的参数。"></a>Unet：用于预测<code>noise</code>，是带有Conditional的Unet(x,t)，通过self-attention模块把Position Embedding后的时间步$\mathbf{T}$融合到Unet中，从而能更好对于不同时刻的 $\mathbf{X}_T$进行噪声的预测。训练后模型保存的就是这块的参数。</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Unet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        dim,</span></span><br><span class="line"><span class="params">        init_dim = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        out_dim = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        dim_mults=(<span class="params"><span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span></span>),				<span class="comment">##对应Unet下采样4个阶段通道数的变换，数值对应变化的倍数</span></span></span><br><span class="line"><span class="params">        channels = <span class="number">3</span>,								  <span class="comment">##输入图像的通道数</span></span></span><br><span class="line"><span class="params">        self_condition = <span class="literal">False</span>,				<span class="comment">##控制Unet中是否加入自注意力机制。		</span></span></span><br><span class="line"><span class="params">        resnet_block_groups = <span class="number">8</span>,</span></span><br><span class="line"><span class="params">        learned_variance = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        learned_sinusoidal_cond = <span class="literal">False</span>,						</span></span><br><span class="line"><span class="params">        random_fourier_features = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        learned_sinusoidal_dim = <span class="number">16</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># determine dimensions</span></span><br><span class="line"></span><br><span class="line">        self.channels = channels</span><br><span class="line">        self.self_condition = self_condition</span><br><span class="line">        input_channels = channels * (<span class="number">2</span> <span class="keyword">if</span> self_condition <span class="keyword">else</span> <span class="number">1</span>)			</span><br><span class="line"></span><br><span class="line">        init_dim = default(init_dim, dim)  <span class="comment">##init_dim有定义则设置为init_dim，无就默认dim</span></span><br><span class="line">        self.init_conv = nn.Conv2d(input_channels, init_dim, <span class="number">7</span>, padding = <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        dims = [init_dim, *<span class="built_in">map</span>(<span class="keyword">lambda</span> m: dim * m, dim_mults)]</span><br><span class="line">        in_out = <span class="built_in">list</span>(<span class="built_in">zip</span>(dims[:-<span class="number">1</span>], dims[<span class="number">1</span>:]))</span><br><span class="line"></span><br><span class="line">        block_klass = partial(ResnetBlock, groups = resnet_block_groups)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># time embeddings</span></span><br><span class="line"></span><br><span class="line">        time_dim = dim * <span class="number">4</span></span><br><span class="line"></span><br><span class="line">        self.random_or_learned_sinusoidal_cond = learned_sinusoidal_cond <span class="keyword">or</span> random_fourier_features</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.random_or_learned_sinusoidal_cond:</span><br><span class="line">            sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)</span><br><span class="line">            fourier_dim = learned_sinusoidal_dim + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sinu_pos_emb = SinusoidalPosEmb(dim)		<span class="comment">##正弦位置编码</span></span><br><span class="line">            fourier_dim = dim</span><br><span class="line"></span><br><span class="line">        self.time_mlp = nn.Sequential(		<span class="comment">##对步长进行一个编码和转换的MLP</span></span><br><span class="line">            sinu_pos_emb,</span><br><span class="line">            nn.Linear(fourier_dim, time_dim),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Linear(time_dim, time_dim)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># layers</span></span><br><span class="line"></span><br><span class="line">        self.downs = nn.ModuleList([])</span><br><span class="line">        self.ups = nn.ModuleList([])</span><br><span class="line">        num_resolutions = <span class="built_in">len</span>(in_out)</span><br><span class="line">	<span class="comment">##堆叠下采样残差块</span></span><br><span class="line">        <span class="keyword">for</span> ind, (dim_in, dim_out) <span class="keyword">in</span> <span class="built_in">enumerate</span>(in_out):</span><br><span class="line">            is_last = ind &gt;= (num_resolutions - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            self.downs.append(nn.ModuleList([</span><br><span class="line">                block_klass(dim_in, dim_in, time_emb_dim = time_dim),</span><br><span class="line">                block_klass(dim_in, dim_in, time_emb_dim = time_dim),</span><br><span class="line">                Residual(PreNorm(dim_in, LinearAttention(dim_in))),</span><br><span class="line">                Downsample(dim_in, dim_out) <span class="keyword">if</span> <span class="keyword">not</span> is_last <span class="keyword">else</span> nn.Conv2d(dim_in, dim_out, <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">            ]))</span><br><span class="line"></span><br><span class="line">        mid_dim = dims[-<span class="number">1</span>]</span><br><span class="line">        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)</span><br><span class="line">        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))</span><br><span class="line">        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)</span><br><span class="line">	<span class="comment">##堆叠下采样残差块</span></span><br><span class="line">        <span class="keyword">for</span> ind, (dim_in, dim_out) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">reversed</span>(in_out)):</span><br><span class="line">            is_last = ind == (<span class="built_in">len</span>(in_out) - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            self.ups.append(nn.ModuleList([</span><br><span class="line">                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),</span><br><span class="line">                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),</span><br><span class="line">                Residual(PreNorm(dim_out, LinearAttention(dim_out))),</span><br><span class="line">                Upsample(dim_out, dim_in) <span class="keyword">if</span> <span class="keyword">not</span> is_last <span class="keyword">else</span>  nn.Conv2d(dim_out, dim_in, <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">            ]))</span><br><span class="line"></span><br><span class="line">        default_out_dim = channels * (<span class="number">1</span> <span class="keyword">if</span> <span class="keyword">not</span> learned_variance <span class="keyword">else</span> <span class="number">2</span>)</span><br><span class="line">        self.out_dim = default(out_dim, default_out_dim)</span><br><span class="line"></span><br><span class="line">        self.final_res_block = block_klass(dim * <span class="number">2</span>, dim, time_emb_dim = time_dim)</span><br><span class="line">        self.final_conv = nn.Conv2d(dim, self.out_dim, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li>GassianDiffusion：将整个diffusion process和reverse diffusion集成在一起的类，载入了Unet模型。可以进行任意时间步的扩散，以及单步采样和整个时间步长的采样循环。同时提供了训练时计算Loss的过程，整个<code>forward</code>过程返回的就是训练的Loss。</li>
</ol>
<h4 id="训练过程：-1"><a href="#训练过程：-1" class="headerlink" title="训练过程："></a>训练过程：</h4><p>看decoder后分类变不变，或者latent diffusion后分类变不变</p>
<p>ldm换l1，unet通道倍数1，2，2，2</p>
<p>ae的训练encode，只在encoder里除10.</p>
]]></content>
      <categories>
        <category>深度学习</category>
        <category>Diffusion model</category>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Diffusion model</tag>
        <tag>代码讲解</tag>
      </tags>
  </entry>
  <entry>
    <title>Next设置背景与文本框的透明度</title>
    <url>/2023/03/27/17-53-08/</url>
    <content><![CDATA[<h2 id="设置Hexo背景"><a href="#设置Hexo背景" class="headerlink" title="设置Hexo背景"></a>设置Hexo背景</h2><p>找到next主题下面的source/css/_schemes/Mist/index.styl，添加如下代码：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">body &#123; </span><br><span class="line">    background:url(/uploads/1.png);</span><br><span class="line">    background-repeat: no-repeat;</span><br><span class="line">    background-attachment:fixed; //不重复</span><br><span class="line">    background-size: cover;      //填充</span><br><span class="line">    background-position:100% 100%;</span><br><span class="line">&#125;       </span><br></pre></td></tr></table></figure></p>
<h2 id="设置文本框的透明度"><a href="#设置文本框的透明度" class="headerlink" title="设置文本框的透明度"></a>设置文本框的透明度</h2><p>可以再添加如下代码：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.post-block &#123;</span><br><span class="line">  background: rgba(255,255,255,.85) none repeat scroll !important;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><em>rgba的第四个参数是控制透明度，其余控制文章背景的颜色。</em></p>
<p>其余美化参考这篇<a href="https://blog.csdn.net/lyshark_csdn/article/details/124939308?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-124939308-blog-93797964.235^v27^pc_relevant_default&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3">博客</a></p>
]]></content>
      <categories>
        <category>Hexo配置</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>《Physically Adversarial Infrared Patches with Learnable Shapes and Locations》阅读笔记</title>
    <url>/2023/04/02/20-50-07/</url>
    <content><![CDATA[<h2 id="《Physically-Adversarial-Infrared-Patches-with-Learnable-Shapes-and-Locations》"><a href="#《Physically-Adversarial-Infrared-Patches-with-Learnable-Shapes-and-Locations》" class="headerlink" title="《Physically Adversarial Infrared Patches with Learnable Shapes and Locations》"></a>《Physically Adversarial Infrared Patches with Learnable Shapes and Locations》</h2><h3 id="CVPR-2023"><a href="#CVPR-2023" class="headerlink" title="CVPR 2023"></a>CVPR 2023</h3><p><img src="/2023/04/02/20-50-07/image-20230403165457032.png" alt="image-20230403165457032" style="zoom:34%;"></p>
<blockquote>
<p>一句话：针对红外目标检测场景，设计了一种对抗性红外补丁，通过隔热材料来改变目标热成像的图像，通过可学习的补丁形状和位置，进一步增加了物理世界攻击的可行性。</p>
</blockquote>
<hr>
<p><img src="/2023/04/02/20-50-07/image-20230403175255441.png" alt="image-20230403175255441" style="zoom:50%;"></p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>​        红外成像中的目标检测以其在恶劣环境下具有较强的抗干扰性而著称，被广泛应用于安防监视、遥感等安全关键任务中。因此有必要对红外目标检测的物理对抗鲁棒性进行评估。以往的对抗攻击都是从RGB的角度产生的扰动，对红外相机来说是无法捕获到的。所以需要一种针对性的攻击方法。</p>
<hr>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><p>现在也有一些相关工作：</p>
<ul>
<li>针对红外目标检测不可感知的对抗攻击，但是属于修改红外图像中的像素值而非物理世界的攻击。</li>
<li>通过小灯泡来模拟热源，从而改变物体的红外辐射分布，来产生对抗扰动，但局限性很大，一个是不隐蔽且不容易实施，需要设计电路板来点亮小灯泡，第二是它是产生新的热源而不是隐蔽覆盖它们，受限于一些需要隐蔽热源的场景。</li>
<li>通过穿上包裹全身的对抗性衣服，可以从不同角度去攻击探测器。具体操作是先设计2D的QR图案，然后转换成3D的衣服，最后将特殊红外材料贴到指定位置。总之攻击成本非常高和复杂。</li>
</ul>
<p><img src="/2023/04/02/20-50-07/image-20230403175401024.png" alt="image-20230403175401024" style="zoom:50%;"></p>
<ul>
<li><p>本文的方法是通过减少热辐射，而且只需要设计Patch的形状和位置即可达到攻击效果，有很强的隐蔽性。</p>
<hr>
<h3 id="Problem-Formuation"><a href="#Problem-Formuation" class="headerlink" title="Problem Formuation"></a>Problem Formuation</h3><h5 id="目标检测："><a href="#目标检测：" class="headerlink" title="目标检测："></a>目标检测：</h5><p>主要基于行人检测任务，对于所有的候选框 ${b_i \mid i=1, \ldots, n}$的置信度 ${s_i \mid i=1, \ldots, n}$，选择置信度最高的框作为最终目标，当大于一个阈值的时候算检测到行人。</p>
<h5 id="攻击目标："><a href="#攻击目标：" class="headerlink" title="攻击目标："></a>攻击目标：</h5><p>最小化候选边框最大置信度的分数，使其低于检测阈值，从而检测不到行人。即最小化如下攻击损失：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{a t t a c k}\left(f\left(\boldsymbol{x}_{a d v}\right)\right)=\max _{i \in\{1, \ldots, n\}}\left(s_i\right)</script><h5 id="对抗样本的构建："><a href="#对抗样本的构建：" class="headerlink" title="对抗样本的构建："></a>对抗样本的构建：</h5><script type="math/tex; mode=display">
\boldsymbol{x}_{a d v}=\boldsymbol{x} \odot(\mathbf{1}-\boldsymbol{M})+\hat{\boldsymbol{x}} \odot \boldsymbol{M}</script><p>其中 $\boldsymbol{M} \in{0,1}^{h \times w}$是用于约束隔热材料的形状和位置掩码，最开始的时候为了能优化设计了软 $\boldsymbol{M}$，范围是在 $[0,1]^{h \times w}$ 的连续值，最后不断优化接近 ${0,1}^{h \times w}$</p>
<p>而 $\hat{\boldsymbol{x}}$表示隔热材料返回的热成像的像素值，但实际很难控制，这是很大程度取决于隔热材料的物理性质，热反射率等等，而通常整个Patch都是一样的材料，选定了材料就相当于确定了 $\hat{\boldsymbol{x}}$，基本整个图案都是相同的值，这里尽可能让它趋近于0，从而后续设计对抗样本只需要去优化 Mask的形状和位置。</p>
<p><img src="/2023/04/02/20-50-07/image-20230403195454965.png" alt="image-20230403195454965" style="zoom:50%;"></p>
<h5 id="MASK的优化目标："><a href="#MASK的优化目标：" class="headerlink" title="MASK的优化目标："></a>MASK的优化目标：</h5><p>利用梯度的优化来求解最优的的 $\boldsymbol{M}$</p>
<ol>
<li><p>$\boldsymbol{M}$中的像素应该尽可能聚集在一起。</p>
</li>
<li><p>$\boldsymbol{M}$中的像素值应该尽可能接近0和1。</p>
<p><strong>这样可以使优化后MASK更好的设计隔热材料，从而转换到物理世界的攻击更容易实现。</strong></p>
</li>
</ol>
</li>
</ul>
<hr>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h5 id="如何聚合-boldsymbol-M-​中的像素-："><a href="#如何聚合-boldsymbol-M-​中的像素-：" class="headerlink" title="如何聚合 $\boldsymbol{M}$​中的像素 ："></a>如何聚合 $\boldsymbol{M}$​中的像素 ：</h5><p>通过设计一个局部聚合系数去控制，优化使系数越大，也就意味着越聚合。</p>
<script type="math/tex; mode=display">
C_i=\frac{\mathcal{K} * \boldsymbol{A}_{3 \times 3}}{k_i\left(k_i-1\right)}=\frac{\mathcal{K} * \boldsymbol{A}_{3 \times 3}}{56}</script><p>对每个像素点都定义一个局部聚合系数 $C_i$，$\mathcal{K}$表示临接点的边数矩阵，$*$表示卷积操作。 $\boldsymbol{A}_{3 \times 3}$表示一个衰减因子矩阵，由 $\alpha_j$ 组成。</p>
<script type="math/tex; mode=display">
\alpha_j=V_j \times \frac{1}{\left|L_j\right|} \sum_{v_k \in L_j} V_k</script><p><img src="/2023/04/02/20-50-07/image-20230403205115813.png" alt="image-20230403205115813" style="zoom:40%;"></p>
<p>最后得到整个 $\boldsymbol{M}$的聚合程度，表示为  $C(M) = \sum_{j=1}^h \sum_{k=1}^w C_{j k} \cdot M_{j k}$，优化使其最大。最小化Loss表示为：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{a g g}(\boldsymbol{M})=-C(\boldsymbol{M})=-\frac{1}{h w} \sum_{j=1}^h \sum_{k=1}^w C_{j k} \cdot M_{j k}</script><hr>
<h5 id="如何二值化："><a href="#如何二值化：" class="headerlink" title="如何二值化："></a>如何二值化：</h5><p><strong>通过MSE约束：</strong></p>
<script type="math/tex; mode=display">
\mathcal{L}_{M S E}(\mathcal{H}(\boldsymbol{M}), \boldsymbol{I})=\frac{1}{h w} \sum_{j=1}^h \sum_{k=1}^w\left(\mathcal{H}\left(M_{j k}\right)-1\right)^2</script><p>其中 $\boldsymbol{I}$为全1的矩阵， $\mathcal{H}(M_{jk})$是一个类似ReLU的函数，其中 $M_{jk}$小于阈值的时候置1，大于阈值的时候保持不变。这样可以只约束大于阈值的部分，从而更接近1。</p>
<p>同时为了使 $\boldsymbol{M}$稀疏化，额外引入对它本身的一个L1约束。总的二值化损失为：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text {binary }}(\boldsymbol{M})=\|\boldsymbol{M}\|_1+\alpha \cdot \mathcal{L}_{M S E}(\mathcal{H}(\boldsymbol{M}), \boldsymbol{I})</script><p>因此最后整个Loss Function为：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{o b j}=\mathcal{L}_{a t t a c k}\left(f\left(\boldsymbol{x}_{a d v}\right)\right)+\lambda_1 \mathcal{L}_{\text {binary }}(\boldsymbol{M})+\lambda_2 \mathcal{L}_{a g g}</script><script type="math/tex; mode=display">
\boldsymbol{M}^*=\arg \min _{\boldsymbol{M}} \mathcal{L}_{o b j}\left(f\left(\boldsymbol{x}_{a d v}\right)\right)</script><hr>
<h5 id="通过带动量的梯度下降优化："><a href="#通过带动量的梯度下降优化：" class="headerlink" title="通过带动量的梯度下降优化："></a>通过带动量的梯度下降优化：</h5><script type="math/tex; mode=display">
\begin{gathered}
\boldsymbol{x}_{t+1}^{a d v}=\boldsymbol{x} \odot\left(1-\boldsymbol{M}_{t+1}\right)+\hat{\boldsymbol{x}} \odot \boldsymbol{M}_{t+1} \\\\
\boldsymbol{M}_{t+1}=\left(\boldsymbol{M}_t-\epsilon \cdot g_{t+1}\right) \odot \boldsymbol{M}_{o b j} \\\\
g_{t+1}=\mu \cdot g_t+\frac{\nabla_{\boldsymbol{M}} \mathcal{L}_{o b j}\left(f\left(\boldsymbol{x}_{a d v}\right), y ; \boldsymbol{M}_t\right)}{\left\|\nabla_{\boldsymbol{M}} \mathcal{L}_{o b j}\left(f\left(\boldsymbol{x}_{a d v}\right), y ; \boldsymbol{M}_t\right)\right\|_1}
\end{gathered}</script><p>其中 $\boldsymbol{M}_{o b j}$是目标检测对象的原始定位的框的掩码，因为我们并不想优化目标对象框以外的地方。</p>
<hr>
<h5 id="具体流程："><a href="#具体流程：" class="headerlink" title="具体流程："></a>具体流程：</h5><h5 id><a href="#" class="headerlink" title></a><img src="/2023/04/02/20-50-07/image-20230403213524550.png" alt="image-20230403213524550" style="zoom:50%;"><img src="/2023/04/02/20-50-07/image-20230403220326896.png" alt="image-20230403220326896"></h5><hr>
<h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><h5 id="Dataset：FLIR-ADAS-dataset"><a href="#Dataset：FLIR-ADAS-dataset" class="headerlink" title="Dataset：FLIR ADAS dataset"></a>Dataset：FLIR ADAS dataset</h5><h5 id="Target-detector-YOLOv3"><a href="#Target-detector-YOLOv3" class="headerlink" title="Target detector:    YOLOv3"></a>Target detector:    YOLOv3</h5><h5 id="Metrics：ASR（攻击成功率）和AP（PR曲线下面的面积）"><a href="#Metrics：ASR（攻击成功率）和AP（PR曲线下面的面积）" class="headerlink" title="Metrics：ASR（攻击成功率）和AP（PR曲线下面的面积）"></a>Metrics：ASR（攻击成功率）和AP（PR曲线下面的面积）</h5><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/2023/04/02/20-50-07/image-20230403215238273.png" alt="image-20230403215238273" style="zoom:60%;"></p>
<p>相比之前两种方法，本文的攻击AP达到了SOTA的效果，把原先检测器的100%AP降到12.05%。</p>
<hr>
<h5 id="消融实验："><a href="#消融实验：" class="headerlink" title="消融实验："></a>消融实验：</h5><h6 id="位置和形状的影响："><a href="#位置和形状的影响：" class="headerlink" title="位置和形状的影响："></a>位置和形状的影响：</h6><p><img src="/2023/04/02/20-50-07/image-20230403230428975.png" alt="image-20230403230428975" style="zoom:60%;"></p>
<p><img src="/2023/04/02/20-50-07/image-20230403230510193.png" alt="image-20230403230510193" style="zoom:50%;"></p>
<h6 id="损失函数的影响："><a href="#损失函数的影响：" class="headerlink" title="损失函数的影响："></a>损失函数的影响：</h6><p><img src="/2023/04/02/20-50-07/image-20230403231133217.png" alt="image-20230403231133217" style="zoom:50%;"></p>
<p><img src="/2023/04/02/20-50-07/image-20230403230615465.png" alt="image-20230403230615465" style="zoom:50%;"></p>
<p>约束聚合效果的Loss添加后虽然攻击性能下降了，但是这对于转换到物理世界的实施至关重要。</p>
<hr>
<h5 id="物理世界的攻击："><a href="#物理世界的攻击：" class="headerlink" title="物理世界的攻击："></a>物理世界的攻击：</h5><p>同样也达到了SOTA的效果：</p>
<p><img src="/2023/04/02/20-50-07/image-20230403220244357.png" alt="image-20230403220244357"></p>
<p><img src="/2023/04/02/20-50-07/image-20230403231323853.png" alt="image-20230403231323853" style="zoom:50%;"><img src="/2023/04/02/20-50-07/image-20230403231621541.png" alt="image-20230403231621541" style="zoom:50%;"></p>
<p>但是本文的方法制作物理世界的红外贴片的时长花销是制作红外衣服的 $1/20$。</p>
<h5 id="对于物理世界的车辆检测："><a href="#对于物理世界的车辆检测：" class="headerlink" title="对于物理世界的车辆检测："></a>对于物理世界的车辆检测：</h5><p><img src="/2023/04/02/20-50-07/image-20230403232034168.png" alt="image-20230403232034168" style="zoom:67%;"></p>
<p>表明这种攻击可以应用到其他任务上。</p>
<hr>
<h3 id="防御红外对抗补丁"><a href="#防御红外对抗补丁" class="headerlink" title="防御红外对抗补丁"></a>防御红外对抗补丁</h3><ul>
<li><p>空间平滑</p>
</li>
<li><p>随机添加噪声</p>
</li>
<li><p>对抗训练</p>
<p><img src="/2023/04/02/20-50-07/image-20230403232241490.png" alt="image-20230403232241490" style="zoom:50%;"></p>
</li>
</ul>
<p>像空间平滑，随机加噪这种防御方法针对这种攻击效果是极差的，因为这种聚合的且二值分明的补丁受这种平滑和一些扰动的影响是极小的。</p>
<hr>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>本文提出了一种可以学习形状和位置的对抗性红外补丁，可以应用于物理世界的目标检测模型，通过隔热材料使模型失效，达到很高的攻击成功率，且极易容易制作，制作成本同时也很低。</p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>对抗样本</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
        <tag>对抗样本</tag>
      </tags>
  </entry>
  <entry>
    <title>在Typora里插入图片(并在Hexo本地能显示)</title>
    <url>/2023/03/28/20-45-40/</url>
    <content><![CDATA[<h2 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h2><p><img src="/2023/03/28/20-45-40/image-20230328210953868.png" alt="image-20230328210953868"></p>
<span id="more"></span>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h3 id="先下载Typora并配置偏好设置"><a href="#先下载Typora并配置偏好设置" class="headerlink" title="先下载Typora并配置偏好设置"></a>先下载Typora并配置偏好设置</h3><p><img src="/2023/03/28/20-45-40/image-20230328211235474.png" alt="image-20230328211235474" style="zoom:50%;"></p>
<h3 id="并且在博客根目录下安装-hexo-asset-image"><a href="#并且在博客根目录下安装-hexo-asset-image" class="headerlink" title="并且在博客根目录下安装 hexo-asset-image"></a>并且在博客根目录下安装 <code>hexo-asset-image</code></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install https://github.com/CodeFalling/hexo-asset-image --save</span><br></pre></td></tr></table></figure>
<p>修改 <code>_config.yml</code>中 <code>post_asset_folder</code>设置为<code>true</code></p>
<p>此后每 <code>hexo new page</code>都会产生一个同名的文件夹，用于存放图片。</p>
<h3 id="安装插件-hexo-renderer-marked"><a href="#安装插件-hexo-renderer-marked" class="headerlink" title="安装插件 hexo-renderer-marked"></a>安装插件 <code>hexo-renderer-marked</code></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-renderer-marked --save</span><br></pre></td></tr></table></figure>
<p>并且在<code>_config.yml</code>中加入如下设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">marked:</span><br><span class="line">  prependRoot: true</span><br><span class="line">  postAsset: true</span><br></pre></td></tr></table></figure>
<h3 id="大功告成"><a href="#大功告成" class="headerlink" title="大功告成"></a>大功告成</h3><p>之后在哪复制的或者截图的就可以直接粘贴进Typora了</p>
]]></content>
      <categories>
        <category>Hexo配置</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2023/03/27/15-38-50/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>hexo-bug</title>
    <url>/2023/03/31/22-41-53/</url>
    <content><![CDATA[<h2 id="Hexo遇到的BUG"><a href="#Hexo遇到的BUG" class="headerlink" title="Hexo遇到的BUG"></a>Hexo遇到的BUG</h2><h4 id="编辑数学公式时："><a href="#编辑数学公式时：" class="headerlink" title="编辑数学公式时："></a>编辑数学公式时：</h4><p>使用Latex表示公式时连续使用 <code>&#123; &#123;</code>会报错，且无法渲染，需要在括号之间加入空格完美解决。<del>折磨了半天，竟然这么简单的解决了，之前还查了什么导致和markdown冲突，需要改解析的规则</del></p>
]]></content>
  </entry>
</search>
